{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"labeledTrainData.tsv\", header=0, delimiter='\\t', quoting=3)\n",
    "test = pd.read_csv(\"testData.tsv\", header=0, delimiter='\\t', quoting=3)\n",
    "unlabeled_train = pd.read_csv(\"unlabeledTrainData.tsv\", header=0, delimiter='\\t', quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import various model for clening the text\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist(review, remove_stopwords=False):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #\n",
    "    # 2.remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    # 3. convert word to lower case and split\n",
    "    words = review_text.lower().split()\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the punkt tokenizer for sentence splitting\n",
    "import nltk.data\n",
    "\n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "# Define a function to split a review into parsed sentences\n",
    "def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a review into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "#     print(raw_sentences)\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append( review_to_wordlist( raw_sentence, remove_stopwords ))\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(\"300features_40minwords_10context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0514271 , -0.05480901, -0.03706408,  0.0451298 ,  0.03551459,\n",
       "       -0.06432813, -0.01661876, -0.00520615, -0.08906938, -0.13924482,\n",
       "       -0.07806679,  0.12562075,  0.08069624,  0.05373814,  0.06561399,\n",
       "       -0.00235362, -0.07317895,  0.09190165,  0.02494637,  0.04594135,\n",
       "        0.10622973, -0.03211069, -0.01861409, -0.00083636,  0.02217456,\n",
       "        0.01866037, -0.04152292, -0.0349835 , -0.03670044,  0.02415779,\n",
       "        0.02476616,  0.03164262,  0.00752363,  0.03579576, -0.0991041 ,\n",
       "       -0.01247764, -0.0346579 ,  0.00638266, -0.0077857 , -0.01602524,\n",
       "       -0.00717401,  0.00167522, -0.05680299,  0.07383982,  0.08701462,\n",
       "       -0.05897753, -0.01924523,  0.10350288, -0.02288168, -0.04093151,\n",
       "       -0.01484664, -0.04878024, -0.01388485,  0.01716304, -0.03698753,\n",
       "       -0.00460978, -0.07099182, -0.00913173, -0.03816442, -0.04769471,\n",
       "        0.07382052,  0.08291068, -0.0315371 , -0.04461202, -0.03119381,\n",
       "        0.06610774,  0.09737919, -0.01033472,  0.03383221,  0.02197194,\n",
       "        0.11107924,  0.01317461, -0.00131511, -0.03928538,  0.06218411,\n",
       "        0.01381357, -0.00818661, -0.04058443,  0.03489976,  0.01710682,\n",
       "       -0.00663412, -0.03814837,  0.07703415, -0.10829972,  0.03764474,\n",
       "       -0.0244863 , -0.01268363, -0.00180202,  0.0120969 , -0.05951441,\n",
       "        0.0099918 ,  0.00755367,  0.05771901, -0.1140245 , -0.0601124 ,\n",
       "       -0.0340158 ,  0.0772184 , -0.01828604,  0.04501864, -0.02785068,\n",
       "       -0.03807821, -0.00335707,  0.00948009, -0.03547668, -0.04603575,\n",
       "       -0.04326013,  0.10270657,  0.06537198,  0.03317776, -0.06747496,\n",
       "       -0.00027479, -0.01908278,  0.03133398, -0.00807275, -0.03251215,\n",
       "        0.01089319,  0.01904213,  0.00605112,  0.05939683,  0.04555195,\n",
       "        0.09325015,  0.0050672 , -0.03278136,  0.01517263, -0.0473025 ,\n",
       "        0.07569529,  0.08994918,  0.05325938,  0.07023542, -0.06133634,\n",
       "       -0.04335565, -0.02306912, -0.06321311, -0.01491283,  0.04087039,\n",
       "       -0.01704493, -0.05362485, -0.04664195,  0.03067727,  0.00385033,\n",
       "        0.01463484, -0.00913036,  0.02552549,  0.07138799, -0.00572247,\n",
       "       -0.06924552, -0.08400103, -0.13542937,  0.01295557, -0.08165529,\n",
       "       -0.00260062, -0.0055875 ,  0.08500102, -0.03348294,  0.0689948 ,\n",
       "       -0.117231  , -0.04184873, -0.03019157, -0.00547831, -0.02655869,\n",
       "       -0.07385153,  0.05725592,  0.06207661, -0.04847029,  0.03007969,\n",
       "       -0.00832846,  0.02247132,  0.00897093, -0.00158281,  0.12204632,\n",
       "        0.01702873,  0.04549683, -0.00382443, -0.0752221 ,  0.00947573,\n",
       "        0.02679132, -0.03180454, -0.04717126,  0.0368451 , -0.01097926,\n",
       "       -0.05149179,  0.00167344, -0.03991492,  0.02792483,  0.05084961,\n",
       "       -0.09288359, -0.03184868, -0.01389651,  0.01822528, -0.05290716,\n",
       "       -0.08254383,  0.03633725,  0.01024348,  0.10501749, -0.02200925,\n",
       "        0.08566765,  0.05983026, -0.07629399,  0.0383057 , -0.08724308,\n",
       "        0.07206728, -0.08589797, -0.01826696, -0.0036905 ,  0.03082329,\n",
       "       -0.02525218,  0.04253025,  0.0287033 , -0.10208353, -0.0104316 ,\n",
       "        0.06198443, -0.04547782, -0.01062185,  0.01835319, -0.0520804 ,\n",
       "       -0.10690276,  0.08101531, -0.12740496,  0.05981335, -0.14448616,\n",
       "       -0.08110634,  0.09292306,  0.0588898 ,  0.06887992,  0.05476501,\n",
       "        0.11144707, -0.01457887, -0.00252134,  0.03352169,  0.09786163,\n",
       "        0.06225575, -0.10153631, -0.09374637,  0.04180322,  0.0120987 ,\n",
       "       -0.03809014, -0.04569634,  0.00528252,  0.08391021, -0.036792  ,\n",
       "        0.04235074, -0.07012622,  0.01004239, -0.0413409 , -0.06902221,\n",
       "       -0.01851238, -0.0445474 ,  0.02214706,  0.06304953,  0.02098816,\n",
       "        0.13553217,  0.00152729,  0.00442631,  0.06949827, -0.11687568,\n",
       "        0.01140151, -0.08097131, -0.07781602, -0.10032164,  0.03447929,\n",
       "       -0.07803901, -0.0505881 , -0.14679138, -0.04333217,  0.0841811 ,\n",
       "        0.08446924,  0.00954556, -0.04709932, -0.01247381, -0.05897883,\n",
       "       -0.11209843, -0.07827725,  0.01529454, -0.06357124,  0.08942384,\n",
       "        0.03405842,  0.07076731,  0.11073761, -0.01907987, -0.01876026,\n",
       "        0.07523334,  0.03218137,  0.04588062, -0.06168322,  0.07336457,\n",
       "        0.16154757, -0.02658775, -0.06757819, -0.02498392, -0.03666366,\n",
       "       -0.05104365, -0.07496881,  0.0219464 , -0.05481052,  0.01563287,\n",
       "        0.08817914,  0.00519216, -0.02406353, -0.08338958, -0.03135274], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"flower\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Make sure that numpy is imported\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.\n",
    "    # \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # Given a set of reviews (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # \n",
    "    # Initialize a counter\n",
    "    counter = 0.\n",
    "    # \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    # \n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "       #\n",
    "       # Print a status message every 1000th review\n",
    "       if counter%1000. == 0.:\n",
    "           print(\"Review %d of %d\" % (counter, len(reviews)))\n",
    "       # \n",
    "       # Call the function (defined above) that makes average feature vectors\n",
    "       reviewFeatureVecs[counter] = makeFeatureVec(review, model, \\\n",
    "           num_features)\n",
    "       #\n",
    "       # Increment the counter\n",
    "       counter = counter + 1.\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file /usr/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-04b54e627c74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mclean_train_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mreview_to_wordlist\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m         \u001b[0mremove_stopwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrainDataVecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetAvgFeatureVecs\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mclean_train_reviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating average feature vecs for test reviews\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-9d267908b96c>\u001b[0m in \u001b[0;36mgetAvgFeatureVecs\u001b[0;34m(reviews, model, num_features)\u001b[0m\n\u001b[1;32m     44\u001b[0m        \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m        \u001b[0;31m# Call the function (defined above) that makes average feature vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m        \u001b[0mreviewFeatureVecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakeFeatureVec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m            \u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m        \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m        \u001b[0;31m# Increment the counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# ****************************************************************\n",
    "# Calculate average feature vectors for training and testing sets,\n",
    "# using the functions we defined above. Notice that we now use stop word\n",
    "# removal.\n",
    "num_features = 300\n",
    "clean_train_reviews = []\n",
    "for review in train[\"review\"]:\n",
    "    clean_train_reviews.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "\n",
    "trainDataVecs = getAvgFeatureVecs( clean_train_reviews, model, num_features )\n",
    "\n",
    "print(\"Creating average feature vecs for test reviews\")\n",
    "clean_test_reviews = []\n",
    "for review in test[\"review\"]:\n",
    "    clean_test_reviews.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "\n",
    "testDataVecs = getAvgFeatureVecs( clean_test_reviews, model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16490"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.38068218e-03,  -6.26454428e-02,  -1.63734323e-04, ...,\n",
       "         -4.87488806e-02,  -4.90719161e-04,   7.77191967e-02],\n",
       "       [ -9.39467847e-02,  -5.51806152e-05,   7.60902883e-03, ...,\n",
       "         -3.16449143e-02,  -1.24446005e-01,   6.42076358e-02],\n",
       "       [  1.18126146e-01,   2.26852903e-03,  -1.68994609e-02, ...,\n",
       "         -8.63448605e-02,   1.86871621e-03,   7.55333528e-02],\n",
       "       ..., \n",
       "       [ -2.36577522e-02,  -8.50679800e-02,  -2.29315069e-02, ...,\n",
       "          5.30488119e-02,  -6.13216534e-02,   1.64637044e-02],\n",
       "       [  4.18576486e-02,  -4.97073010e-02,  -5.73279336e-02, ...,\n",
       "         -3.17289606e-02,  -2.48052180e-03,   9.36293900e-02],\n",
       "       [  4.84285504e-02,  -7.94675350e-02,   4.23087962e-02, ...,\n",
       "         -1.62440315e-02,  -1.18006162e-01,   9.66558699e-03]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
